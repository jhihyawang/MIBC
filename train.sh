#!/bin/bash

# ==========================================
# ç’°å¢ƒè¨­å®š 
# ==========================================

# è«‹å°‡ä»¥ä¸‹è·¯å¾‘æ”¹ç‚ºæ‚¨é›»è…¦ä¸Šçš„å¯¦éš›ä½ç½®
DATA_ROOT="processed_datasets"  # åœ–ç‰‡æ ¹ç›®éŒ„
CSV_DIR="csv/three_classes"       # CSV æª”æ¡ˆç›®éŒ„

TRAIN_CSV="${CSV_DIR}/train_labels.csv"
VAL_CSV="${CSV_DIR}/val_labels.csv"
TEST_CSV="${CSV_DIR}/test_labels.csv"
SAVE_DIR="./0103_baseon_breastlevel_decisionrule"

# ==========================================
# è¨“ç·´è¶…åƒæ•¸è¨­å®š
# ==========================================

# æƒ³è¦è·‘çš„æ¨¡å‹åˆ—è¡¨
BACKBONES=("resnet18" "resnet50" "efficientnet_b0" "efficientnet_b3" "convnext_tiny" "convnext_small")
# BACKBONES=("resnet50" "efficientnet_b0" "efficientnet_b5" "convnext_tiny" "convnext_small")

# æƒ³è¦è·‘çš„æ¶æ§‹åˆ—è¡¨
ARCHITECTURES=("baseline" "ipsi" "bi" "cross_view")    # é¸é …: cross_view, baseline, ipsi, bi

# æƒ³è¦è·‘çš„æ‹¼æ¥æ–¹å¼åˆ—è¡¨
CONCATE_METHODS=("concat" "concat_linear" "concat_mlp")
DESISION_RULES=("max" "rule")

# ç¡¬é«”ç›¸é—œåƒæ•¸
BATCH_SIZE=4     
ACCUM_STEPS=8
EPOCHS=50
LR=1e-4
WD=1e-4
IMG_H=1024
IMG_W=512
# è‡ªå‹•ç”Ÿæˆå¯¦é©— ID (åŒ…å«æ™‚é–“æˆ³è¨˜ï¼Œé¿å…è¦†è“‹)
TIMESTAMP=$(date +"%m%d_%H%M")

# ==========================================
# é–‹å§‹è¿´åœˆè¨“ç·´
# ==========================================

for BACKBONE in "${BACKBONES[@]}"; do
    for ARCHITECTURE in "${ARCHITECTURES[@]}"; do
        for CONCATE_METHOD in "${CONCATE_METHODS[@]}"; do
            for DECISION_RULE in "${DESISION_RULES[@]}"; do
                EFFECTIVE_BS=$((BATCH_SIZE * ACCUM_STEPS))
                EXP_ID="${BACKBONE}_${ARCHITECTURE}_${CONCATE_METHOD}_${DECISION_RULE}_effbs${EFFECTIVE_BS}_${TIMESTAMP}"
                
                echo "========================================================"
                echo "ğŸš€ Starting Training..."
                echo "   Experiment ID: ${EXP_ID}"
                echo "   Backbone:      ${BACKBONE}"
                echo "   Architecture:  ${ARCHITECTURE}"
                echo "   Batch Size:    ${BATCH_SIZE} (Accum: ${ACCUM_STEPS} => Effective: ${EFFECTIVE_BS})"
                echo "========================================================"

                # åŸ·è¡Œ Python è…³æœ¬
                uv run main.py \
                    --csv_train "${TRAIN_CSV}" \
                    --csv_val "${VAL_CSV}" \
                    --csv_test "${TEST_CSV}" \
                    --root_dir "${DATA_ROOT}" \
                    --save_dir "${SAVE_DIR}" \
                    --num_classes 3 \
                    --experiment_id "${EXP_ID}" \
                    --backbone "${BACKBONE}" \
                    --architecture "${ARCHITECTURE}" \
                    --concate_method "${CONCATE_METHOD}" \
                    --decision_rule "${DECISION_RULE}" \
                    --batch_size ${BATCH_SIZE} \
                    --gradient_accumulation_steps ${ACCUM_STEPS} \
                    --img_height ${IMG_H} \
                    --img_width ${IMG_W} \
                    --num_epochs ${EPOCHS} \
                    --lr ${LR} \
                    --weight_decay ${WD} \
                    --pretrained \
                    --mixed_precision \
                    --use_class_weights
                    
                # æª¢æŸ¥åŸ·è¡Œçµæœ
                if [ $? -eq 0 ]; then
                    echo "âœ… Training [${EXP_ID}] Completed Successfully!"
                    echo "--------------------------------------------------------"
                else
                    echo "âŒ Training [${EXP_ID}] Failed."
                    echo "--------------------------------------------------------"
                    # é‡åˆ°éŒ¯èª¤æ˜¯å¦è¦åœæ­¢ï¼Ÿå¦‚æœä¸å¸Œæœ›åœæ­¢æ•´å€‹è¿´åœˆï¼Œè«‹è¨»è§£æ‰ä¸‹é¢é€™è¡Œ exit 1
                    exit 1
                fi
                
                # (é¸ç”¨) æ¸…é™¤ GPU å¿«å–ï¼Œé¿å…ä¸åŒå¯¦é©—é–“çš„å¹²æ“¾
                # python -c "import torch; torch.cuda.empty_cache()"
            done
        done
    done
done