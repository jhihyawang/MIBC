import cv2
import os 
import pandas as pd
import random  
import numpy as np
# pip install opencv-python pandas numpy matplotlib
def crop_black_borders(img, threshold=5, margin_ratio=0.02):
    """
    img: numpy array, shape (H, W) æˆ– (H, W, 3)
    threshold: > threshold è¦–ç‚ºã€Œæœ‰è¨Šè™Ÿã€
    margin_ratio: åœ¨æ‰¾åˆ°çš„ bounding box å¤–å¤šä¿ç•™çš„æ¯”ä¾‹
    """
    # å¦‚æœæ˜¯ 3 channelï¼Œå…ˆè½‰ç°éšåˆ¤æ–· maskï¼Œä½† crop æ™‚ä¿ç•™åŸé€šé“
    if img.ndim == 3:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    else:
        gray = img

    # å»ºç«‹ã€ŒéèƒŒæ™¯ã€mask
    mask = gray > threshold

    # å¦‚æœæ•´å¼µåœ–éƒ½å°æ–¼ thresholdï¼Œå°±ä¸ crop
    if not mask.any():
        return img

    ys, xs = np.where(mask)
    y_min, y_max = ys.min(), ys.max()
    x_min, x_max = xs.min(), xs.max()

    h, w = gray.shape
    margin_y = int(h * margin_ratio)
    margin_x = int(w * margin_ratio)

    y_min = max(y_min - margin_y, 0)
    y_max = min(y_max + margin_y, h - 1)
    x_min = max(x_min - margin_x, 0)
    x_max = min(x_max + margin_x, w - 1)

    # æ³¨æ„ slicing çš„ end index è¦ +1
    if img.ndim == 3:
        cropped = img[y_min:y_max+1, x_min:x_max+1, :]
    else:
        cropped = img[y_min:y_max+1, x_min:x_max+1]

    return cropped

def all_flip_to_right(img, side='R'):
    """
    å¦‚æœæ˜¯å·¦ä¹³(R)ï¼Œå‰‡æ°´å¹³ç¿»è½‰æˆå³ä¹³(L)
    """
    if side == 'R':
        return cv2.flip(img, 1)  # æ°´å¹³ç¿»è½‰
    return img

def resize_padding_2_1(img, target_width=512):
    """
    Resize and pad image to 2:1 aspect ratio.
    - å‚ç›´ padding ä¸€å¾‹è²¼åœ¨ã€Œä¸‹æ–¹ã€
    - æ°´å¹³ padding ä¸€å¾‹è²¼åœ¨ã€Œå³é‚Šã€
    """

    h, w = img.shape[:2]

    # é€™è£¡å¦‚æœä½ æ˜¯æƒ³è¦ H:W = 2:1 çš„é•·åœ–ï¼Œå¯ä»¥ç”¨ï¼š
    target_height = target_width * 2
    # å¦‚æœä½ è¦ W:H = 2:1 çš„æ©«åœ–ï¼Œæ”¹æˆï¼š
    # target_height = target_width // 2

    # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹
    scale = min(target_width / w, target_height / h)
    new_w = max(1, int(round(w * scale)))
    new_h = max(1, int(round(h * scale)))

    # resize
    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_CUBIC)

    # å»ºç«‹é»‘åº• canvas
    if resized.ndim == 3:
        channels = resized.shape[2]
        padded = np.zeros((target_height, target_width, channels), dtype=resized.dtype)
    else:
        padded = np.zeros((target_height, target_width), dtype=resized.dtype)

    # ğŸ”¸é—œéµï¼šè²¼åœ¨å·¦ä¸Šè§’ â†’ padding è‡ªç„¶å°±è·‘åˆ°ã€Œä¸‹æ–¹ + å³é‚Šã€
    y_offset = 0
    x_offset = 0

    padded[y_offset:y_offset + new_h, x_offset:x_offset + new_w] = resized

    return padded

def apply_clahe(img, clip_limit=1.5, tile_grid_size=(8, 8)):
    # Ensure the image is grayscale
    if img.ndim == 3:  # If the image has 3 channels (e.g., RGB)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    return clahe.apply(img)

def normalize_for_calc(img, low=1):
    """
    åªåšä½ç«¯å‰ªè£ï¼Œä¿ç•™é«˜äº®ç´°ç¯€
    """
    img_f = img.astype(np.float32)
    nonzero = img_f[img_f > 0]
    if nonzero.size < 10:
        return img

    p_low = np.percentile(nonzero, low)

    # åªå‰ªä½ï¼Œä¸å‰ªé«˜
    img_f = np.clip(img_f, p_low, None)

    # ç”¨å¯¦éš› max ç•¶ä¸Šé™ï¼Œä¿ç•™ highlight å°¾ç«¯
    max_v = img_f.max()
    if max_v <= p_low:
        return img

    img_f = (img_f - p_low) / (max_v - p_low + 1e-6)
    img_f = np.clip(img_f * 255.0, 0, 255)
    return img_f.astype(np.uint8)

def process_image_pipeline(ori_img, save_root="Category 4"):
    # è®€å–å½±åƒ
    img = cv2.imread(ori_img)
    img_name = os.path.splitext(os.path.basename(ori_img))[0]
    folder_name = os.path.basename(os.path.dirname(ori_img))
    save_path = os.path.join(save_root, folder_name, img_name)
    print(f"å„²å­˜è·¯å¾‘: {save_path}")
    
    # Preprocessing steps
    cropped = crop_black_borders(img, threshold=5, margin_ratio=0.02)
    side = 'R' if 'R-' in os.path.basename(ori_img) else 'L'
    flipped = all_flip_to_right(cropped, side=side)
    resized_padded = resize_padding_2_1(flipped, target_width=512)
    normalized = normalize_for_calc(resized_padded, low=1.0)
    img_clahe = apply_clahe(normalized, clip_limit=0.7, tile_grid_size=(8, 8))

    # result = [resized_padded, img_clahe, normal_highpass]
    result = [img_clahe]
    for i, res in enumerate(result):
        suffix = ["processed_datasets"][i]
        print(f"å„²å­˜: {suffix}/{save_path}.jpg")
        new_save_path = os.path.join(suffix, save_root, folder_name, img_name)
        os.makedirs(os.path.dirname(new_save_path), exist_ok=True)
        cv2.imwrite(f"{new_save_path}.jpg", res)

def process_all(input_root="dataset"):
    for category in os.listdir(input_root):
        category_path = os.path.join(input_root, category)
        print(f"Processing category: {category}")
        if not os.path.isdir(category_path):
            continue
        for patient_id in os.listdir(category_path):
            patient_path = os.path.join(category_path, patient_id)
            if not os.path.isdir(patient_path):
                continue
            for img_file in os.listdir(patient_path):
                if img_file.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tiff')):
                    img_path = os.path.join(patient_path, img_file)
                    try:
                        process_image_pipeline(img_path, save_root=os.path.join(category))
                    except Exception as e:
                        print(f"âš ï¸ è™•ç†å¤±æ•—: {img_path}, éŒ¯èª¤: {e}")

### split dataset and generate csv ###
VALID_VIEWS = ['L-CC', 'R-CC', 'L-MLO', 'R-MLO']

def stratified_split(df, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, seed=42):
    """
    åˆ†å±¤æŠ½æ¨£, ç¢ºä¿æ¯å€‹é¡åˆ¥åœ¨ train/val/test ä¸­çš„æ¯”ä¾‹æ¥è¿‘æŒ‡å®šæ¯”ä¾‹
    ä¸¦ä¸”æ¯å€‹é¡åˆ¥è‡³å°‘æœ‰ 1 ç­†è³‡æ–™åœ¨æ¯å€‹é›†åˆï¼ˆå¦‚æœè©²é¡åˆ¥ç¸½æ•¸ >= 3ï¼‰
    é€™å€‹ç‰ˆæœ¬ä½¿ç”¨å››æ¨äº”å…¥ä¾†è¨ˆç®—æ¯å€‹é›†åˆçš„å¤§å°ï¼Œä»¥æ¸›å°‘åå·®ã€‚
    åƒæ•¸:
    - df: åŒ…å« 'label' æ¬„ä½çš„ DataFrame
    - train_ratio, val_ratio, test_ratio: ä¸‰å€‹é›†åˆçš„æ¯”ä¾‹å’Œæ‡‰ç‚º 1.0
    - seed: éš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿å¯é‡ç¾æ€§
    å›å‚³:
    - train_df, val_df, test_df: åˆ†å‰²å¾Œçš„ DataFrames
    """
    random.seed(seed)
    train_list, val_list, test_list = [], [], []

    for label in sorted(df['label'].unique()):
        df_label = df[df['label'] == label].sample(frac=1, random_state=seed)
        n_total = len(df_label)
        
        # ä½¿ç”¨å››æ¨äº”å…¥è¨ˆç®—å„é›†åˆå¤§å°
        n_train = max(1, round(n_total * train_ratio))
        n_val = max(1, round(n_total * val_ratio))
        
        # ç¢ºä¿ç¸½æ•¸æ­£ç¢ºï¼štest é›†åˆå¸æ”¶æ‰€æœ‰èª¤å·®
        n_test = max(1, n_total - n_train - n_val)
        
        # è™•ç†é‚Šç•Œæƒ…æ³ï¼šç¸½å’Œè¶…é n_total
        if n_train + n_val + n_test > n_total:
            excess = n_train + n_val + n_test - n_total
            # å„ªå…ˆå¾æœ€å¤§çš„é›†åˆæ¸›å°‘
            if n_train >= n_val and n_train > excess:
                n_train -= excess
            elif n_val > excess:
                n_val -= excess
            else:
                n_test -= excess
        
        # è™•ç†é‚Šç•Œæƒ…æ³ï¼šç¸½å’Œå°æ–¼ n_totalï¼ˆç†è«–ä¸Šä¸æ‡‰ç™¼ç”Ÿï¼‰
        elif n_train + n_val + n_test < n_total:
            n_test += (n_total - (n_train + n_val + n_test))
        
        # ç¢ºä¿æ¯å€‹é›†åˆè‡³å°‘æœ‰ 1 ç­†è³‡æ–™ï¼ˆå¦‚æœé¡åˆ¥ç¸½æ•¸ >= 3ï¼‰
        if n_total >= 3:
            n_train = max(1, n_train)
            n_val = max(1, n_val)
            n_test = max(1, n_test)
        
        train_list.append(df_label.iloc[:n_train])
        val_list.append(df_label.iloc[n_train:n_train+n_val])
        test_list.append(df_label.iloc[n_train+n_val:n_train+n_val+n_test])

    train_df = pd.concat(train_list).sample(frac=1, random_state=seed).reset_index(drop=True)
    val_df = pd.concat(val_list).sample(frac=1, random_state=seed).reset_index(drop=True)
    test_df = pd.concat(test_list).sample(frac=1, random_state=seed).reset_index(drop=True)

    return train_df, val_df, test_df


def generate_multiview_csvs(base_dir, output_dir,
                            train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, seed=42):
    random.seed(seed)
    patients_data = []

    print(f"\nğŸ“‚ Scanning dataset folder: {base_dir}")
    
    for category in sorted(os.listdir(base_dir)):
        category_path = os.path.join(base_dir, category)
        if not os.path.isdir(category_path):
            continue
        try:
            label = int(category.replace("Category ", ""))
            if label == 6:
                print(f"â­ï¸ Skip Category {label}")
                continue
            elif label == 0:
                final_label = 0
            elif label==1 or label == 2 or label ==3:
                final_label = 1
            else:
                final_label = 2
        except ValueError:
            print(f"âš ï¸ Skip unrecognized folder name '{category}'")
            continue

        for patient_folder in os.listdir(category_path):
            patient_path = os.path.join(category_path, patient_folder)
            if not os.path.isdir(patient_path):
                continue

            patient_entry = {
                'patient_id': f"{category}/{patient_folder}",
                'label': final_label,
            }

            for img_file in os.listdir(patient_path):
                if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    view_name = os.path.splitext(img_file)[0]
                    if view_name in VALID_VIEWS:
                        patient_entry[view_name] = os.path.join(category, patient_folder, img_file)

            patients_data.append(patient_entry)

    df = pd.DataFrame(patients_data)
    df = df.reindex(columns=VALID_VIEWS + ['label', 'patient_id'])

    missing_mask = df[VALID_VIEWS].isna().any(axis=1)
    if missing_mask.any():
        print("\nâš ï¸ Patients missing some views:")
        for _, row in df[missing_mask].iterrows():
            missing_views = [v for v in VALID_VIEWS if pd.isna(row[v])]
            print(f"  - {row['patient_id']} missing {', '.join(missing_views)}")

    df = df.dropna(subset=VALID_VIEWS)

    # åˆ†å±¤æŠ½æ¨£ï¼ˆä½¿ç”¨æ”¹é€²ç‰ˆï¼‰
    train_df, val_df, test_df = stratified_split(df, train_ratio, val_ratio, test_ratio, seed)

    os.makedirs(output_dir, exist_ok=True)
    train_df.to_csv(os.path.join(output_dir, "train_labels.csv"), index=False)
    val_df.to_csv(os.path.join(output_dir, "val_labels.csv"), index=False)
    test_df.to_csv(os.path.join(output_dir, "test_labels.csv"), index=False)

    print(f"\nâœ… Output complete: {len(df)} patients")
    print(f"  Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}")
    print(f"ğŸ“ Output folder: {output_dir}")

    # æ¯å€‹é¡åˆ¥çµ±è¨ˆï¼ˆåŒ…å«å¯¦éš›æ¯”ä¾‹ï¼‰
    print("\nğŸ“Š Dataset counts per class (stratified with rounding):")
    for label in sorted(df['label'].unique()):
        n_total_c = (df['label'] == label).sum()
        n_train_c = (train_df['label'] == label).sum()
        n_val_c   = (val_df['label'] == label).sum()
        n_test_c  = (test_df['label'] == label).sum()
        
        actual_train_ratio = n_train_c / n_total_c if n_total_c > 0 else 0
        actual_val_ratio = n_val_c / n_total_c if n_total_c > 0 else 0
        actual_test_ratio = n_test_c / n_total_c if n_total_c > 0 else 0
        
        print(f"  Category {label} (Total: {n_total_c}):")
        print(f"    Train={n_train_c} ({actual_train_ratio:.1%}), "
              f"Val={n_val_c} ({actual_val_ratio:.1%}), "
              f"Test={n_test_c} ({actual_test_ratio:.1%})")

if __name__ == "__main__":
    base_dir = "/media/stoneyew/512ssd/datasets"
    process_all(input_root=base_dir)
    output_dir = "csv/three_class"
    generate_multiview_csvs(
        base_dir=base_dir,
        output_dir=output_dir,
        train_ratio=0.7,
        val_ratio=0.1,
        test_ratio=0.2,
        seed=42
    )